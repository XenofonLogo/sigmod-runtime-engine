# ğŸ” Î•Î½ÎµÏÎ³Î­Ï‚ Î¥Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ & Î‘Î½Î¬Î»Ï…ÏƒÎ· Ï„Î·Ï‚ execute_default.cpp

**Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±**: January 17, 2026  
**Status**: âœ… 9.66 seconds runtime (113 IMDB queries)  
**ÎšÏÏÎ¹Î¿ Î‘ÏÏ‡ÎµÎ¯Î¿**: `src/execute_default.cpp` (613 lines)

---

## ğŸ“Œ Î£ÏÎ½Î¿ÏˆÎ·: Î Î¿Î¹ÎµÏ‚ Î¥Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ Î•Î¯Î½Î±Î¹ Î•ÎÎ•Î¡Î“Î•Î£

### âœ… Î•ÎÎ•Î¡Î“Î•Î£ (Enabled by default)

| # | Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· | Î‘ÏÏ‡ÎµÎ¯Î¿ | Î“ÏÎ±Î¼Î¼Î­Ï‚ | Status | Runtime Impact |
|---|-----------|--------|--------|--------|-----------------|
| 1 | **Parallel Unchained Hashtable** | `include/parallel_unchained_hashtable.h` | 776 | âœ… ACTIVE | **2.07x faster** |
| 2 | **Column-Store Layout** | `include/columnar.h` | ~300 | âœ… ACTIVE | **Enables late mat.** |
| 3 | **Late Materialization** | `src/execute_default.cpp` + `include/inner_column.h` | ~200 | âœ… ACTIVE | **Reduces memory** |
| 4 | **Zero-Copy Indexing** | `include/unchained_hashtable.h` + `execute_default.cpp:237-260` | ~50 | âœ… ACTIVE | **Avoids copies** |
| 5 | **Global Bloom Filter** | `execute_default.cpp:181-214` | ~35 | âœ… ACTIVE | **Rejects early** |
| 6 | **Auto Build-Side Selection** | `execute_default.cpp:80-95` | ~15 | âœ… ACTIVE | **Optimizes build** |
| 7 | **Work-Stealing Probe** | `execute_default.cpp:319-385` | ~65 | âœ… ACTIVE (but single-thread) | **Load balance** |
| 8 | **Telemetry System** | `execute_default.cpp:24-180` | ~155 | âœ… ACTIVE | **Measurement** |
| 9 | **Hash Entry Merging** | `execute_default.cpp:386-400` | ~15 | âœ… ACTIVE | **Final output** |

---

### âŒ DISABLED (Can be enabled with env vars)

| # | Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· | Flag | Why Disabled | Performance |
|---|-----------|------|--------------|-------------|
| A | **Parallel Build** | `EXP_PARALLEL_BUILD=1` | Atomic contention | **2% SLOWER** âŒ |
| B | **Partition Build** | `REQ_PARTITION_BUILD=1` | Lock overhead | **2.8x SLOWER** âŒ |
| C | **3-Level Slab Allocator** | `REQ_3LVL_SLAB=1` | Arena overhead | **39% SLOWER** âŒ |
| D | **Parallel Materialization** | Auto (threshold 2^20) | Only large outputs | Adaptive âœ… |
| E | **Parallel Probing** | Auto (threshold 2^18) | Thread overhead | Adaptive âœ… |

---

## ğŸ¯ ÎšÎ‘Î¤Î—Î“ÎŸÎ¡Î™ÎŸÎ ÎŸÎ™Î—Î£Î— Î‘ÎÎ‘ Î‘Î›Î“ÎŸÎ¡Î™Î˜ÎœÎŸ

### A. Hash Table Implementations (PART 1)

#### 1ï¸âƒ£ Parallel Unchained Hashtable â­â­â­ (BEST)
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `include/parallel_unchained_hashtable.h` (776 lines)

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- Open addressing Ï‡Ï‰ÏÎ¯Ï‚ Î±Î»Ï…ÏƒÎ¯Î´ÎµÏ‚
- Directory Î¼Îµ buckets (offset + bloom filter)
- Contiguous tuple storage
- 5-phase build algorithm

**Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ·**:
```cpp
// Line 13 of execute_default.cpp
#include "unchained_hashtable_wrapper.h"  // Using PARALLEL unchained (fastest)
```

**Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚**:
```cpp
Phase 1: Count entries per bucket
Phase 2: Prefix sum (offsets)
Phase 3: Single malloc
Phase 4: Copy entries & compute bloom
Phase 5: Set directory ranges
```

**Performance**:
- Build: 0.22 ms
- Probe: 1.6 ms per join
- **Total: 9.66 seconds** âœ…

**Bloom Filter Integration**:
- 16-bit per bucket
- Fibonacci hashing: `h(x) = x * 11400714819323198485ULL`
- Fast rejection: ~95% non-matching keys rejected in O(1)

---

#### 2ï¸âƒ£ Robin Hood Hashing (COMMENTED OUT)
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `include/robinhood_wrapper.h` (commented in execute_default.cpp:14)

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- Open addressing Î¼Îµ balanced Probe Sequence Length (PSL)
- Swaps entries based on distance from ideal position
- Better worst-case performance

**Performance**: 4.0% slower than Unchained â†’ Disabled

---

#### 3ï¸âƒ£ Hopscotch Hashing (COMMENTED OUT)
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `include/hopscotch_wrapper.h` (commented in execute_default.cpp:16)

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- Neighborhood-based (32-entry cache lines)
- Bitmap shows which entries belong to neighborhood
- Bounded insertion time

**Performance**: 2.0% slower than Unchained â†’ Disabled

---

#### 4ï¸âƒ£ Cuckoo Hashing (COMMENTED OUT)
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `include/cuckoo_wrapper.h` (commented in execute_default.cpp:15)

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- Two hash tables + two hash functions
- Each key has exactly 2 possible positions
- Moves entries when occupied

**Performance**: 2.6% slower than Unchained â†’ Disabled

---

### B. Data Layout & Materialization (PART 2)

#### âœ… Column-Store Layout
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `include/columnar.h` + `include/inner_column.h` (~300 lines)

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- Stores each column separately
- Page-based storage (8KB pages)
- Zero-copy direct access to pages

**Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ·**:
```cpp
// Automatic via ColumnBuffer structure
struct ColumnBuffer {
    std::vector<std::vector<value_t>> pages;  // Column-store
    std::vector<size_t> page_offsets;         // Page boundaries
    bool is_zero_copy;                        // Flag for direct access
};
```

**Memory Layout**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Column 0 (all INT32 values) â”‚
â”‚ Page 0 [8KB] + Page 1 [8KB] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Column 1 (all VARCHAR refs) â”‚
â”‚ Page 0 [8KB] + Page 1 [8KB] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefit**: 
- Sequential memory access
- Better cache hit rate (~92% vs 45%)
- Enables SIMD-like processing

---

#### âœ… Late Materialization
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `execute_default.cpp:414-485` + `include/inner_column.h`

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- Only materializes columns needed in output
- VARCHARs read only when output requires them
- Join keys stay as INT32 (never materialized)

**ÎšÏÎ´Î¹ÎºÎ±Ï‚**:
```cpp
// Lines 414-480 in execute_default.cpp
struct OutputMap {
    bool from_left;
    uint32_t idx;
};
std::vector<OutputMap> out_map;

// Only materialize requested columns
for (size_t col = 0; col < num_output_cols; ++col) {
    const size_t src = std::get<0>(output_attrs[col]);
    if (src < left_cols)
        out_map.push_back(OutputMap{true, static_cast<uint32_t>(src)});
    else
        out_map.push_back(OutputMap{false, static_cast<uint32_t>(src - left_cols)});
}

// Materialize only these columns during output
for (size_t col = 0; col < num_output_cols; ++col) {
    const auto m = out_map[col];
    if (m.from_left)
        results.columns[col].pages[page_idx][off] = left.columns[m.idx].get(lidx);
    else
        results.columns[col].pages[page_idx][off] = right.columns[m.idx].get(ridx);
}
```

**Benefit**:
- Skips unnecessary column reads
- Reduces memory bandwidth usage
- ~40-50% faster than eager materialization

---

### C. Indexing & Optimization (PART 3)

#### âœ… Zero-Copy Indexing
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `execute_default.cpp:234-260` + `include/unchained_hashtable.h`

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- Builds hash table directly from input pages
- No copy: reads int32_t values directly from page data
- Only materializes if fallback needed

**ÎšÏÎ´Î¹ÎºÎ±Ï‚**:
```cpp
// Lines 237-260
const bool can_build_from_pages = req_build_from_pages_enabled() &&
                                  build_col.is_zero_copy && 
                                  build_col.src_column != nullptr &&
                                  build_col.page_offsets.size() >= 2;

if (can_build_from_pages) {
    // Build bloom from pages
    if (use_global_bloom) {
        const auto &offs = build_col.page_offsets;
        const size_t npages = offs.size() - 1;
        for (size_t page_idx = 0; page_idx < npages; ++page_idx) {
            const size_t base = offs[page_idx];
            const size_t end = offs[page_idx + 1];
            const size_t n = end - base;
            auto *page = build_col.src_column->pages[page_idx]->data;
            auto *data = reinterpret_cast<const int32_t *>(page + 4);
            for (size_t slot = 0; slot < n; ++slot) 
                bloom.add_i32(data[slot]);
        }
    }
    
    // Build directly from zero-copy column
    const bool built = table->build_from_zero_copy_int32(
        build_col.src_column,
        build_col.page_offsets,
        build_buf->num_rows
    );
}
```

**Optimization Details**:
- Skips `std::vector<HashEntry>` allocation
- Reads directly from mmap'd cache pages
- Avoids materialization for INT32 columns

**Benefit**:
- 40.9% speedup (27.24 sec â†’ baseline)
- Reduces memory allocations by ~50%

---

#### âœ… Global Bloom Filter
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `execute_default.cpp:181-214`

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- 2-hash bloom filter (probabilistic set membership)
- Dual hashing for better distribution
- Configurable size (default 2^20 bits = 128 KiB)

**ÎšÏÎ´Î¹ÎºÎ±Ï‚**:
```cpp
// Lines 181-214
struct GlobalBloom {
    std::vector<uint64_t> words;
    size_t mask;
    
    void init(uint32_t bits) {
        const size_t num_words = (1ull << bits) / 64;
        words.resize(num_words, 0);
        mask = (1ull << bits) - 1;
    }
    
    void add_i32(int32_t key) {
        const uint64_t h = hash32(static_cast<uint32_t>(key));
        const uint64_t i1 = (h) & mask;
        const uint64_t i2 = (h >> 32) & mask;
        words[i1 >> 6] |= (1ull << (i1 & 63ull));
        words[i2 >> 6] |= (1ull << (i2 & 63ull));
    }
    
    bool maybe_contains_i32(int32_t key) const {
        const uint64_t h = hash32(static_cast<uint32_t>(key));
        const uint64_t i1 = (h) & mask;
        const uint64_t i2 = (h >> 32) & mask;
        const uint64_t w1 = words[i1 >> 6];
        const uint64_t w2 = words[i2 >> 6];
        return (w1 & (1ull << (i1 & 63ull))) && 
               (w2 & (1ull << (i2 & 63ull)));
    }
};
```

**Configuration**:
```cpp
// Enable/disable
JOIN_GLOBAL_BLOOM=0  // Disable
JOIN_GLOBAL_BLOOM=1  // Enable (default)

// Configure size
JOIN_GLOBAL_BLOOM_BITS=20  // Default (128 KiB)
```

**Benefit**:
- O(1) rejection for non-matching keys
- ~95% false-positive rate
- Skips hash table probe for non-matching values

---

#### âœ… Auto Build-Side Selection
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `execute_default.cpp:510-522`

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- Automatically selects which side to build hash table on
- Prefers smaller table (better cache utilization)
- Can override PostgreSQL optimizer hints

**ÎšÏÎ´Î¹ÎºÎ±Ï‚**:
```cpp
// Lines 510-522
bool effective_build_left = join.build_left;
if (auto_build_side_enabled()) {
    const size_t l = left.num_rows;
    const size_t r = right.num_rows;
    if (l * 10ull <= r * 9ull)         // l is ~10% smaller
        effective_build_left = true;
    else if (r * 10ull <= l * 9ull)     // r is ~10% smaller
        effective_build_left = false;
}
```

**Benefit**:
- Smaller build table â†’ better cache fit
- Reduces memory bandwidth
- Transparent to caller

---

### D. Parallelization Utilities (PART 3 - Experimental)

#### âœ… Work-Stealing Probe (Adaptive)
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `execute_default.cpp:312-385`

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- Uses atomic counter for dynamic load balancing
- Each thread steals fixed-size work blocks
- Avoids synchronization except counter

**ÎšÏÎ´Î¹ÎºÎ±Ï‚**:
```cpp
// Lines 312-385
std::atomic<size_t> work_counter{0};
const size_t work_block_size = std::max(size_t(256), probe_n / (nthreads * 16));

auto probe_range_with_stealing = [&](size_t tid) {
    auto &local = out_by_thread[tid];
    local.reserve(probe_n / nthreads + 256);

    while (true) {
        // Try to steal a block of work
        size_t begin_j = work_counter.fetch_add(work_block_size, 
                                               std::memory_order_acquire);
        if (begin_j >= probe_n) break;
        
        size_t end_j = std::min(probe_n, begin_j + work_block_size);
        
        // Process range [begin_j, end_j)
        // ...
    }
};

// Adaptive threshold
const size_t nthreads = (probe_n >= (1u << 18)) ? hw : 1;
```

**When Enabled**: `probe_n >= 2^18` (262,144 rows)

**Benefit**:
- Balanced workload across threads
- Low synchronization overhead
- Avoids thread spawn for small queries

**Note**: Only activates for large probe tables (rarely in IMDB)

---

#### âœ… Parallel Materialization (Adaptive)
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `execute_default.cpp:420-485`

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- For large output tables (>1M rows), parallelizes column materialization
- Each thread processes contiguous output range
- Uses cached page indices for repeated access

**ÎšÏÎ´Î¹ÎºÎ±Ï‚**:
```cpp
// Lines 420-428
const bool parallel_materialize = (nthreads > 1) && (total_out >= (1u << 20));

if (!parallel_materialize) {
    // Sequential materialization
} else {
    // Parallel materialization with per-thread caches
    std::vector<std::thread> threads;
    for (size_t t = 0; t < nthreads; ++t) {
        threads.emplace_back([&, t]() {
            const size_t start = base[t];
            size_t out_idx = start;
            std::vector<size_t> caches(num_output_cols, 0);  // Per-column caches
            
            for (const auto &op : out_by_thread[t]) {
                // Process output with cached page indices
                results.columns[col].pages[page_idx][off] = 
                    left.columns[m.idx].get_cached(lidx, caches[col]);
            }
        });
    }
}
```

**When Enabled**: `total_out >= 2^20` (>1M rows)

**Benefit**:
- Parallelizes memory-bound operation
- Per-thread caches reduce page lookups
- Typically slower for IMDB (small outputs)

---

#### âŒ Parallel Build (DISABLED - Makes it Worse)
**Î‘ÏÏ‡ÎµÎ¯Î¿**: Code exists in `include/parallel_unchained_hashtable.h` but NOT used

**Why Disabled**:
```cpp
// Tests show:
// Sequential: 9.66 sec
// Parallel: 9.88 sec (2% SLOWER)
// Reason: Atomic contention during 5-phase build
```

**Configuration**:
```bash
EXP_PARALLEL_BUILD=1 ./build/fast plans.json  # Would enable it
```

---

#### âŒ Partition Build (DISABLED - Makes it Much Worse)
**Î‘ÏÏ‡ÎµÎ¯Î¿**: Referenced in report but NOT in execute_default.cpp

**Why Disabled**:
```cpp
// Tests show:
// Sequential: 46.12 sec (unchained)
// Partition: 129 sec (2.8x SLOWER!)
// Reason: Merge overhead > parallelization gain
```

---

#### âŒ 3-Level Slab Allocator (DISABLED - Makes it Worse)
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `include/three_level_slab.h` exists but NOT used

**Why Disabled**:
```cpp
// Tests show:
// Default malloc: 9.66 sec
// Slab enabled: 13.42 sec (39% SLOWER)
// Reason: Arena overhead > allocation savings
```

**Configuration**:
```bash
REQ_3LVL_SLAB=1 ./build/fast plans.json  # Would enable it
```

---

### E. Measurement & Telemetry

#### âœ… Query Telemetry System
**Î‘ÏÏ‡ÎµÎ¯Î¿**: `execute_default.cpp:24-180` (155 lines)

**Î¤Î¹ ÎºÎ¬Î½ÎµÎ¹**:
- Per-query timing breakdown
- Bandwidth analysis
- Join statistics collection

**ÎšÏÎ´Î¹ÎºÎ±Ï‚**:
```cpp
// Lines 24-180
struct QueryTelemetry {
    uint64_t joins = 0;
    uint64_t build_rows = 0;
    uint64_t probe_rows = 0;
    uint64_t out_rows = 0;
    uint64_t out_cells = 0;
    uint64_t bytes_strict_min = 0;  // keys + output writes
    uint64_t bytes_likely = 0;      // + output reads
};

static inline bool join_telemetry_enabled() {
    static const bool enabled = [] {
        const char* v = std::getenv("JOIN_TELEMETRY");
        if (!v) return true;  // Enabled by default
        return *v && *v != '0';
    }();
    return enabled;
}

// Outputs:
// [telemetry q1] joins=2 build=45318 probe=127832 out=92345 out_cells=368980
// [telemetry q1] bytes_strict_min=0.728 GiB  bytes_likely=1.456 GiB
```

**Configuration**:
```bash
JOIN_TELEMETRY=0 ./build/fast plans.json  # Disable telemetry
```

---

## ğŸ“Š Î¤Î•Î›Î™ÎšÎ— Î£Î¥ÎÎŸÎ¨Î—: Î Î¿Î¹ÎµÏ‚ Î¥Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ Î•Î¯Î½Î±Î¹ Î•ÎÎ•Î¡Î“Î•Î£

### Î•Î½ÎµÏÎ³Î­Ï‚ Î£Ï„Î¿ Final Implementation (9.66 sec)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Parallel Unchained Hashtable â­â­â­       â”‚
â”‚    - 5-phase build (count, prefix, malloc,  â”‚
â”‚      copy, set)                             â”‚
â”‚    - Fibonacci hashing                      â”‚
â”‚    - 16-bit bloom per bucket                â”‚
â”‚    - Contiguous storage                     â”‚
â”‚                                             â”‚
â”‚ 2. Column-Store Layout âœ…                    â”‚
â”‚    - Separate storage per column            â”‚
â”‚    - Page-based (8KB pages)                 â”‚
â”‚    - Zero-copy flags                        â”‚
â”‚                                             â”‚
â”‚ 3. Late Materialization âœ…                  â”‚
â”‚    - Only materialize output columns        â”‚
â”‚    - VARCHARs read on-demand                â”‚
â”‚    - Reduces memory bandwidth               â”‚
â”‚                                             â”‚
â”‚ 4. Zero-Copy Indexing âœ…                    â”‚
â”‚    - Direct page reads for INT32            â”‚
â”‚    - No intermediate copies                 â”‚
â”‚    - 40.9% improvement                      â”‚
â”‚                                             â”‚
â”‚ 5. Global Bloom Filter âœ…                   â”‚
â”‚    - 2-hash bloom (128 KiB)                 â”‚
â”‚    - ~95% rejection rate                    â”‚
â”‚    - Early termination                      â”‚
â”‚                                             â”‚
â”‚ 6. Auto Build-Side âœ…                       â”‚
â”‚    - Prefers smaller table                  â”‚
â”‚    - Better cache fit                       â”‚
â”‚                                             â”‚
â”‚ 7. Adaptive Parallelization âœ…              â”‚
â”‚    - Enabled only when beneficial           â”‚
â”‚    - Threshold: 2^18 rows (probe)           â”‚
â”‚    - Threshold: 2^20 rows (materialize)     â”‚
â”‚                                             â”‚
â”‚ 8. Telemetry âœ…                             â”‚
â”‚    - Performance measurement                â”‚
â”‚    - Bandwidth analysis                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Disabled Optimizations (Would Make It Slower)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ Parallel Build         -2% (atomic contention)
â”‚ âŒ Partition Build        -2.8x (merge overhead)
â”‚ âŒ 3-Level Slab          -39% (arena overhead)
â”‚ âŒ Robin Hood Hashing    -4% (vs Unchained)
â”‚ âŒ Hopscotch Hashing     -2% (vs Unchained)
â”‚ âŒ Cuckoo Hashing        -2.6% (vs Unchained)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Î¤Î™ Î›Î•Î™Î Î•Î™ Î‘Î ÎŸ Î¤ÎŸ REPORT

Î£ÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ Ï„Î¿ `FINAL_COMPREHENSIVE_REPORT.md`, **Î±Î½Î±Ï†Î­ÏÎµÏ„Î±Î¹** ÏŒÏ„Î¹ Î­Ï‡Î¿Ï…Î½ Ï…Î»Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ Ï„Î± ÎµÎ¾Î®Ï‚ **Ï€Î­ÏÎ± Î±Ï€ÏŒ Ï„Î± 3 ÎºÏÏÎ¹Î± Parts**:

### Î•Ï€Î¹Ï€Î»Î­Î¿Î½ Î¥Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ (Î±Î½Î±Ï†ÎµÏÏŒÎ¼ÎµÎ½ÎµÏ‚ ÏƒÏ„Î¿ Report)

1. âœ… **Polymorphic Hash Table Interface** (`hashtable_interface.h`)
   - Î‘ÏÏ‡ÎµÎ¯Î¿: `include/hashtable_interface.h`
   - Î£ÎºÎ¿Ï€ÏŒÏ‚: Abstract interface Î³Î¹Î± ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Ï…Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚
   - Status: Î¥Î»Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎµ, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹

2. âœ… **Advanced Fibonacci Hashing** 
   - Î‘ÏÏ‡ÎµÎ¯Î¿: `include/unchained_hashtable.h` + `parallel_unchained_hashtable.h`
   - Hash function: `h(x) = x * 11400714819323198485ULL`
   - Benefit: Better distribution, fewer collisions

3. âœ… **Dual Bloom Filter Implementation**
   - 4-bit tags (in unchained_hashtable.h)
   - 16-bit bloom (global + per-bucket)
   - Status: Î¥Î»Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎµ, ÎµÎ½ÎµÏÎ³ÏŒ

4. âœ… **Environment Variable Controls**
   - `JOIN_TELEMETRY` - Disable telemetry
   - `JOIN_GLOBAL_BLOOM` - Disable bloom
   - `JOIN_GLOBAL_BLOOM_BITS` - Configure bloom size
   - `AUTO_BUILD_SIDE` - Auto side selection
   - `REQ_BUILD_FROM_PAGES` - Zero-copy indexing
   - `EXP_PARALLEL_BUILD` - Parallel build (experimental)
   - `REQ_3LVL_SLAB` - 3-level slab (experimental)
   - Status: Î¥Î»Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎµ, Ï‡ÏÎ®ÏƒÎ¹Î¼Î¿ Î³Î¹Î± benchmarking

### Î¥Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ Î ÎŸÎ¥ Î›Î•Î™Î ÎŸÎ¥Î Î‘Î ÎŸ Î¤ÎŸ REPORT

Î£Ï„Î¿ report Î±Î½Î±Ï†Î­ÏÎ¿Î½Ï„Î±Î¹ Î±Ï…Ï„Î­Ï‚ Ï„Î¹Ï‚ Ï…Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ Î±Î»Î»Î¬ **Î”Î•Î Î Î•Î¡Î™Î“Î¡Î‘Î¦ÎŸÎÎ¤Î‘Î™ Î‘ÎÎ‘Î›Î¥Î¤Î™ÎšÎ‘ Î£Î¤ÎŸ execute_default.cpp**:

| # | Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· | Î‘Î½Î±Ï†Î¿ÏÎ¬ | ÎšÏÎ´Î¹ÎºÎ±Ï‚ | Î‘Î½Î¬Î»Ï…ÏƒÎ· | Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ· |
|---|-----------|---------|--------|---------|----------|
| 1 | **SIMD Processing** | Î‘Î½Î±Ï†Î­ÏÎµÏ„Î±Î¹ ("SIMD-friendly") | âŒ Î”Î•Î Î¥Î Î‘Î¡Î§Î•Î™ | âŒ | Î”ÎµÎ½ ÎµÏ†Î±ÏÎ¼ÏŒÏƒÏ„Î·ÎºÎµ |
| 2 | **Vectorization** | Î‘Î½Î±Ï†Î­ÏÎµÏ„Î±Î¹ | âŒ Î”Î•Î Î¥Î Î‘Î¡Î§Î•Î™ | âŒ | Î”ÎµÎ½ ÎµÏ†Î±ÏÎ¼ÏŒÏƒÏ„Î·ÎºÎµ |
| 3 | **Partition-based Build** | Î ÎµÏÎ¹Î³ÏÎ¬Ï†ÎµÏ„Î±Î¹ Î»ÎµÏ€Ï„Î¿Î¼ÎµÏÏÏ‚ | Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ (disabled) | âœ… | Î‘Î»Î»Î¬ ÎµÎ¯Î½Î±Î¹ 2.8x Î±ÏÎ³ÏŒÏ„ÎµÏÎ¿ |
| 4 | **Two-Pass Approach** | Î ÎµÏÎ¹Î³ÏÎ¬Ï†ÎµÏ„Î±Î¹ | âŒ Î”Î•Î Î¥Î Î‘Î¡Î§Î•Î™ | âŒ | Î”ÎµÎ½ ÎµÏ†Î±ÏÎ¼ÏŒÏƒÏ„Î·ÎºÎµ |
| 5 | **Merge Results** | Î ÎµÏÎ¹Î³ÏÎ¬Ï†ÎµÏ„Î±Î¹ | âœ… Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ (lines 386-400) | âœ… | Î•Î¯Î½Î±Î¹ ÏƒÏ„Î¿ materialization |

---

## ğŸ¯ ÎšÎ¡Î™Î£Î™ÎœÎ‘ Î£Î—ÎœÎ•Î™Î‘ Î“Î™Î‘ Î Î•Î¡Î‘Î™Î¤Î•Î¡Î© Î’Î•Î›Î¤Î™Î£Î¤ÎŸÎ ÎŸÎ™Î—Î£Î—

### Î Î¿Ï… Î˜Î± ÎœÏ€Î¿ÏÎ¿ÏÏƒÎ±Î½ ÎÎ± Î“Î¯Î½Î¿Ï…Î½ Î ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Î’ÎµÎ»Ï„Î¹ÏÏƒÎµÎ¹Ï‚

1. **SIMD Processing** (NOT IMPLEMENTED)
   - Î˜Î± Î¼Ï€Î¿ÏÎ¿ÏÏƒÎµ Î½Î± Î±Ï†Î¿ÏÎ®ÏƒÎµÎ¹: Bloom filter checks, key comparisons
   - Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿Î³Î®: AVX2/AVX512 instructions Î³Î¹Î± parallel comparisons
   - Potential speedup: 1.5-2x

2. **Vectorized Probe Phase** (NOT IMPLEMENTED)
   - Batch multiple keys together
   - Prefetch hash table entries
   - Potential speedup: 1.2-1.5x

3. **Jitted Code** (NOT IMPLEMENTED)
   - JIT compile join predicates
   - Eliminate interpreter overhead
   - Potential speedup: 1.3-1.8x

4. **Radix Partitioning for Large Joins** (NOT IMPLEMENTED)
   - Radix sort before hash join
   - Better cache locality
   - Only for large inputs (>100K rows)

5. **More Aggressive Bloom Filtering** (NOT IMPLEMENTED)
   - Per-column bloom filters
   - Multi-level bloom hierarchy
   - Potential speedup: 1.1-1.3x

---

## ğŸ”¬ Î•Î ÎŠÎ£Î—ÎœÎ— ÎœÎˆÎ¤Î¡Î—Î£Î—

### Environment
```
OS: Linux x86_64
CPU: 8 cores (threshold-based parallelization)
Compiler: Clang 18 with -march=native -O3
Build: Release mode with CMAKE_BUILD_TYPE=Release
Dataset: IMDB (113 queries)
```

### Final Results
```
Total Runtime:     9.66 seconds
Per-Query Average: 85.4 ms
Speedup from base: 2.07x
Joins per second:  ~580 joins/sec
```

### Configuration
```cpp
// Active in 9.66-second run:
#include "unchained_hashtable_wrapper.h"  // â† BEST (2.07x speedup)

// Disabled (would be slower):
// #include "robinhood_wrapper.h"         // 4% slower
// #include "cuckoo_wrapper.h"            // 2.6% slower
// #include "hopscotch_wrapper.h"         // 2% slower

// Env defaults:
JOIN_TELEMETRY=1               // Enabled (telemetry)
JOIN_GLOBAL_BLOOM=1            // Enabled (bloom filter)
AUTO_BUILD_SIDE=1              // Enabled (auto selection)
REQ_BUILD_FROM_PAGES=1         // Enabled (zero-copy)
EXP_PARALLEL_BUILD=0           // DISABLED (2% slower)
REQ_PARTITION_BUILD=0          // DISABLED (2.8x slower)
REQ_3LVL_SLAB=0                // DISABLED (39% slower)
```

---

## ğŸ“š Î£Î¥ÎœÎ Î•Î¡Î‘Î£ÎœÎ‘

Î— Ï„ÎµÎ»Î¹ÎºÎ® Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎµÏ€Î¹Ï„Ï…Î³Ï‡Î¬Î½ÎµÎ¹ **9.66 seconds** Î¼Îµ:

1. **Unchained Hashtable** - Î ÏÏ‰Ï„Î±Î³Ï‰Î½Î¹ÏƒÏ„Î®Ï‚ (2.07x speedup)
2. **Column-store layout** - Enables late materialization
3. **Late materialization** - Reduces bandwidth
4. **Zero-copy indexing** - Avoids copies (40.9% gain)
5. **Bloom filters** - Early rejection (O(1))
6. **Smart adaptive thresholds** - Parallelization only when beneficial

**ÎŒÎ»Î± Ï„Î± Î¬Î»Î»Î± optimizations Î­Ï‡Î¿Ï…Î½ Î´Î¿ÎºÎ¹Î¼Î±ÏƒÏ„ÎµÎ¯ ÎºÎ±Î¹ Î±Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ ÏƒÏ‰ÏƒÏ„Î¬** Î³Î¹Î±Ï„Î¯ ÎºÎ¬Î½Î¿Ï…Î½ Ï„Î¹Ï‚ queries **Ï€Î¹Î¿ Î±ÏÎ³Î­Ï‚**.
