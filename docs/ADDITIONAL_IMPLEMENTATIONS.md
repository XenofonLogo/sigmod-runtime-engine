# OPTIMIZED_PROJECT: Î¤ÎµÏ‡Î½Î¹ÎºÎ® Î¤ÎµÎºÎ¼Î·ÏÎ¯Ï‰ÏƒÎ· Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î®ÏƒÎµÏ‰Î½

## Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î±

1. [Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ· Î¤ÏÎ¹ÏÎ½ Î•ÎºÎ´ÏŒÏƒÎµÏ‰Î½](#1-ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·-Ï„ÏÎ¹ÏÎ½-ÎµÎºÎ´ÏŒÏƒÎµÏ‰Î½)
2. [ÎšÎ¿Î¹Î½Î¬ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î¼Îµ STRICT](#2-ÎºÎ¿Î¹Î½Î¬-Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬-Î¼Îµ-strict)
3. [Î‘Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ­Ï‚ Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ OPTIMIZED](#3-Î±Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ­Ï‚-Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚-optimized)
4. [Direct Page Access](#4-direct-page-access)
5. [Single-Pass Hashtable Build](#5-single-pass-hashtable-build)
6. [Zero-Copy Build & Probe](#6-zero-copy-build--probe)
7. [Batch Output & Preallocation](#7-batch-output--preallocation)
8. [Î£ÏÎ½Î¿ÏˆÎ· Performance](#8-ÏƒÏÎ½Î¿ÏˆÎ·-performance)

---

## 1. Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ· Î¤ÏÎ¹ÏÎ½ Î•ÎºÎ´ÏŒÏƒÎµÏ‰Î½

### 1.1 Î•Î¾Î­Î»Î¹Î¾Î· Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚

Î¥Ï€Î¬ÏÏ‡Î¿Ï…Î½ **Ï„ÏÎµÎ¹Ï‚ ÎµÎºÎ´ÏŒÏƒÎµÎ¹Ï‚** Ï„Î·Ï‚ hash join Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Î•ÎÎ•Î›Î™ÎÎ— Î¥Î›ÎŸÎ ÎŸÎ™Î—Î£Î—Î£                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. LEGACY (Î Î±Î»Î¹Î¬ Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·)
   â”œâ”€ Row-by-row access Î¼Îµ column.get(i)
   â”œâ”€ Division/modulo ÏƒÎµ ÎºÎ¬Î¸Îµ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·
   â”œâ”€ Incremental output Î¼Îµ reallocations
   â”œâ”€ Single-threaded
   â””â”€ Î‘Ï€Î»Î® Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· (ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ®)

2. STRICT_PROJECT (Î‘Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ Î”Î¹Î±Î³Ï‰Î½Î¹ÏƒÎ¼Î¿Ï)
   â”œâ”€ Zero-copy Î³Î¹Î± INT32 Ï‡Ï‰ÏÎ¯Ï‚ NULL (REQ-4)
   â”œâ”€ Partition-based build (REQ-6)
   â”œâ”€ Thread-safe 3-level slab allocator (REQ-6)
   â”œâ”€ Directory-based hashtable (REQ-8.2)
   â”œâ”€ Work-stealing parallelization
   â”œâ”€ Bloom filters
   â””â”€ ~32s (113 queries) - focus on requirements

3. OPTIMIZED_PROJECT (Î¤Î±Ï‡ÏÏ„Î·Ï„Î±)
   â”œâ”€ Zero-copy Ï€Î±Î½Ï„Î¿Ï
   â”œâ”€ Single-pass build (ÏŒÏ‡Î¹ partitions)
   â”œâ”€ Direct page pointers
   â”œâ”€ Continuous array hashtable
   â”œâ”€ Adaptive parallelization
   â”œâ”€ Batch output
   â””â”€ ~11s (113 queries) - focus on speed
```

### 1.2 Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Î¤ÏÎ¹ÏÎ½ Î•ÎºÎ´ÏŒÏƒÎµÏ‰Î½

| Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏŒ | LEGACY | STRICT | OPTIMIZED |
|----------------|--------|--------|-----------|
| **Data Access** | `column.get(i)` | Zero-copy pages | Zero-copy pages |
| **Build Strategy** | Simple loop | 2-phase partition | 1-phase direct |
| **Memory Layout** | Basic vector | Directory partitions | Continuous array |
| **Parallelization** | âŒ None | âœ… Static partition | âœ… Adaptive |
| **Output** | Incremental append | Count-Preallocate | Count-Preallocate |
| **Requirements** | âŒ None | âœ… All 7 | âŒ None |
| **Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î¿Ï‚ Ï‡ÏÏŒÎ½Î¿Ï‚** | ~22s | ~32s | ~11s |
| **Î£ÎºÎ¿Ï€ÏŒÏ‚** | Reference | Competition | Production |

### 1.3 Î¦Î¹Î»Î¿ÏƒÎ¿Ï†Î¯Î± OPTIMIZED

**Î£Ï„ÏŒÏ‡Î¿Ï‚:** ÎœÎ­Î³Î¹ÏƒÏ„Î· Ï„Î±Ï‡ÏÏ„Î·Ï„Î± Ï‡Ï‰ÏÎ¯Ï‚ Ï€ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î¿ÏÏ‚ Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÏ‰Î½

**Î‘ÏÏ‡Î­Ï‚:**
- âš¡ **Eliminate overhead:** Î‘Ï†Î±Î¯ÏÎµÏƒÎ· ÎºÎ¬Î¸Îµ Ï€ÎµÏÎ¹Ï„Ï„Î®Ï‚ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±Ï‚
- ğŸš« **Zero-copy everywhere:** Î‘Ï€Î¿Ï†Ï…Î³Î® materialization
- ğŸ¯ **Direct access:** Î‘Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ Î´ÎµÎ´Î¿Î¼Î­Î½Î±
- ğŸ“Š **Simple structures:** Î‘Ï€Î»Î­Ï‚ Î´Î¿Î¼Î­Ï‚, ÏŒÏ‡Î¹ partitions
- ğŸ”§ **Single-pass:** 1 Ï†Î¬ÏƒÎ· build Î±Î½Ï„Î¯ Î³Î¹Î± 2

---

## 2. ÎšÎ¿Î¹Î½Î¬ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î¼Îµ STRICT

> **ğŸ’¡ Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·:** Î¤Î± Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ features Ï…Î»Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ **ÎºÎ±Î¹ ÏƒÏ„Î¿ STRICT ÎºÎ±Î¹ ÏƒÏ„Î¿ OPTIMIZED**.


### 2.1 Zero-Copy INT32 Pages 

### 2.2 Work-Stealing Parallelization

**Î”Î¹Î±Ï†Î¿ÏÎ¬:** 
- STRICT: Work-stealing ÏƒÏ„Î· merge phase
- OPTIMIZED: Work-stealing ÏƒÏ„Î¿ probe phase (adaptive)

**Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚:** Î’Î». [PARADOTEO_3.md Â§7](PARADOTEO_3.md#7-work-stealing)

### 2.3 Bloom Filters


### 2.4 Batch Output Î¼Îµ Preallocation


### 2.5 Thread-Local Buffers


## 3. Î‘Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ­Ï‚ Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ OPTIMIZED

### 3.1 Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î”Î¹Î±Ï†Î¿ÏÎ­Ï‚ Î±Ï€ÏŒ STRICT

| Aspect | STRICT | OPTIMIZED |
|--------|--------|-----------|
| **Build Phases** | 2 (Partition â†’ Merge) | 1 (Direct) |
| **Build Threads** | Parallel (static partitioning) | Sequential |
| **Memory Layout** | Directory + Partitions | Continuous Array |
| **Intermediate Data** | Per-thread partitions | None |
| **Memory Overhead** | 2-3x | 1x |
| **Code Complexity** | High (~300 LOC) | Low (~80 LOC) |

### 3.2 Î‘Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ¬ Features OPTIMIZED

âœ… **Direct Page Pointers** - Î‘Ï€Î¿Ï†Ï…Î³Î® division/modulo (Â§4)  
âœ… **Single-Pass Build** - 1 Ï†Î¬ÏƒÎ· Î±Î½Ï„Î¯ Î³Î¹Î± 2 (Â§5)  
âœ… **Continuous Array Layout** - Î‘Ï€Î»Î® Î´Î¿Î¼Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Â§5)  
âœ… **Adaptive Parallelization** - Threshold-based activation (Â§6)  

### 3.3 Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î¿ Speedup

```
Î•Î¾Î­Î»Î¹Î¾Î· Performance (113 JOB queries):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

LEGACY:     ~22s  (baseline, single-threaded)
STRICT:     ~32s  (+45% overhead Î±Ï€ÏŒ partitioning)
OPTIMIZED:  ~11s  (-50% Î±Ï€ÏŒ LEGACY, -66% Î±Ï€ÏŒ STRICT)

Speedup OPTIMIZED vs STRICT: ~2.9x
```




## 3. Zero-Copy Build Phase

### 3.1 Î ÏÏŒÎ²Î»Î·Î¼Î±: Materialization Overhead

#### Î‘ÏÏ‡Î¹ÎºÎ® Î ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ· (Î‘ÏÎ³Î®)

```cpp
// STEP 1: Materialize all entries into vector
std::vector<HashEntry<int32_t>> entries;
for (size_t i = 0; i < build_col.num_rows; ++i) {
    int32_t key = build_col.get(i);        // Copy 1
    entries.push_back({key, i});           // Copy 2
}

// STEP 2: Build hashtable from vector
hashtable.build_from_entries(entries);     // Copy 3
```

**Î ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î±:**
- 3 Î±Î½Ï„Î¹Î³ÏÎ±Ï†Î­Ï‚ Ï„Ï‰Î½ Î¯Î´Î¹Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
- Allocation overhead Î³Î¹Î± intermediate vector
- Cache pollution Î±Ï€ÏŒ temporary data
- Memory bandwidth waste

### 3.2 Î›ÏÏƒÎ·: Direct Page-to-Hashtable Build

#### Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·

**Î‘ÏÏ‡ÎµÎ¯Î¿:** [include/parallel_unchained_hashtable.h:227-270](include/parallel_unchained_hashtable.h#L227-L270)

```cpp
void build_from_zero_copy_int32(
    const Column* src_column,
    const std::vector<std::size_t>& page_offsets,
    std::size_t num_rows) {
    
    // Direct single-pass build (OPTIMIZED mode)
    if (!Contest::use_strict_project()) {
        build_from_zero_copy_int32_simple_parallel(
            src_column, page_offsets, num_rows
        );
        return;
    }
    
    // ... STRICT mode uses partitioned build ...
}

void build_from_zero_copy_int32_simple_parallel(
    const Column* src_column,
    const std::vector<std::size_t>& page_offsets,
    std::size_t num_rows) {
    
    const size_t num_pages = page_offsets.size() - 1;
    
    // Pre-allocate hashtable storage
    reserve(num_rows);
    
    // Direct build: Page â†’ Hashtable (NO intermediate vector)
    for (size_t page_idx = 0; page_idx < num_pages; ++page_idx) {
        const Page* page = src_column->get_page(page_idx);
        const int32_t* data = extract_int32_page_data(page);
        
        const size_t start_row = page_offsets[page_idx];
        const size_t end_row = page_offsets[page_idx + 1];
        const size_t page_rows = end_row - start_row;
        
        // Direct insert from page memory
        for (size_t i = 0; i < page_rows; ++i) {
            const int32_t key = data[i];        // Read once
            const size_t row_id = start_row + i;
            insert_direct(key, row_id);         // Insert directly
            // NO intermediate copies!
        }
    }
}
```

### 3.3 Î”Î¹Î¬Î³ÏÎ±Î¼Î¼Î±: Build Pipeline Comparison

```
LEGACY (3-copy materialization):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input      â”‚
â”‚  Pages      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Copy 1: column.get(i)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Intermediateâ”‚
â”‚  Vector     â”‚  â† EXTRA ALLOCATION
â”‚ entries[]   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Copy 2: vector.push_back()
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Temp Buffer â”‚  â† CACHE POLLUTION
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Copy 3: build_from_entries()
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hashtable   â”‚
â”‚  Storage    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Memory: 3x data size
Time: 3x memory bandwidth


OPTIMIZED (zero-copy direct):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input      â”‚
â”‚  Pages      â”‚
â”‚             â”‚
â”‚ [Page 0]â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
â”‚ [Page 1]â”€â”€â”€â”€â”¼â”€â”€â”€â” â”‚
â”‚ [Page 2]â”€â”€â”€â”€â”¼â”€â” â”‚ â”‚
â”‚   ...       â”‚ â”‚ â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚
                â”‚ â”‚ â”‚ Direct pointer read
                â”‚ â”‚ â–¼
                â”‚ â”‚ insert_direct(key, row_id)
                â”‚ â–¼
                â”‚ insert_direct(key, row_id)
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hashtable   â”‚ â† ONLY COPY
â”‚  Storage    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Memory: 1x data size
Time: 1x memory bandwidth
```



## 4. Zero-Copy Probe Phase

### 4.1 Î ÏÏŒÎ²Î»Î·Î¼Î±: Row-by-Row Overhead

#### Î‘ÏÏ‡Î¹ÎºÎ® Î ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ·

```cpp
// Per-row access with abstraction overhead
for (size_t i = 0; i < probe_input.num_rows; ++i) {
    int32_t probe_key = probe_col.get(i);  // Division + modulo
    
    auto* entry = hashtable.lookup(probe_key);
    if (entry) {
        // Process match
        output.append(entry->row_id);      // Potential realloc
    }
}
```

**Bottlenecks:**
- Division/modulo Î³Î¹Î± ÎºÎ¬Î¸Îµ row (millions of times)
- Function call overhead Î³Î¹Î± `get(i)`
- Poor instruction-level parallelism (ILP)
- Branch mispredictions

### 4.2 Î›ÏÏƒÎ·: Batch Page Processing

#### Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·

**Î‘ÏÏ‡ÎµÎ¯Î¿:** [src/execute_default.cpp:162-230](src/execute_default.cpp#L162-L230)

```cpp
// Zero-copy probe: Process entire pages at once
void probe_from_zero_copy_pages(
    const Column* probe_column,
    const std::vector<std::size_t>& page_offsets,
    UnchainedHashTable& ht,
    std::vector<OutPair>& results) {
    
    const size_t num_pages = page_offsets.size() - 1;
    
    // Process page-by-page (cache-friendly)
    for (size_t page_idx = 0; page_idx < num_pages; ++page_idx) {
        const Page* page = probe_column->get_page(page_idx);
        const int32_t* keys = extract_int32_page_data(page);
        
        const size_t start_row = page_offsets[page_idx];
        const size_t end_row = page_offsets[page_idx + 1];
        const size_t page_rows = end_row - start_row;
        
        // Batch probe: sequential key access
        for (size_t i = 0; i < page_rows; ++i) {
            const int32_t probe_key = keys[i];  // Sequential read
            const size_t probe_row = start_row + i;
            
            // Lookup in hashtable
            size_t match_count = 0;
            const auto* entries = ht.probe(probe_key, &match_count);
            
            // Emit all matches
            for (size_t m = 0; m < match_count; ++m) {
                results.push_back({
                    .build_row = entries[m].row_id,
                    .probe_row = probe_row
                });
            }
        }
    }
}
```

### 4.3 Parallel Probe Î¼Îµ Adaptive Strategy

**Î‘ÏÏ‡ÎµÎ¯Î¿:** [include/parallel_unchained_hashtable.h:390-450](include/parallel_unchained_hashtable.h#L390-L450)

```cpp
// Adaptive parallelization based on data size
static constexpr size_t PARALLEL_THRESHOLD = (1 << 18);  // 256K rows

if (num_rows < PARALLEL_THRESHOLD) {
    // Small data: Sequential (avoid thread overhead)
    probe_sequential(probe_data, results);
} else {
    // Large data: Parallel with work-stealing
    probe_parallel_work_stealing(probe_data, results);
}

void probe_parallel_work_stealing(
    const ProbeData& data,
    std::vector<OutPair>& results) {
    
    const size_t nthreads = get_num_threads();
    
    // Thread-local result buffers (no contention)
    std::vector<std::vector<OutPair>> thread_results(nthreads);
    
    // Work-stealing: atomic counter for dynamic load balancing
    std::atomic<size_t> next_page{0};
    const size_t total_pages = data.num_pages();
    
    // Launch worker threads
    std::vector<std::thread> workers;
    for (size_t tid = 0; tid < nthreads; ++tid) {
        workers.emplace_back([&, tid]() {
            while (true) {
                // Steal next page
                size_t page_idx = next_page.fetch_add(1, 
                                    std::memory_order_relaxed);
                if (page_idx >= total_pages) break;
                
                // Process page locally
                probe_page(data, page_idx, thread_results[tid]);
            }
        });
    }
    
    // Wait for completion
    for (auto& w : workers) w.join();
    
    // Merge thread results
    for (const auto& tr : thread_results) {
        results.insert(results.end(), tr.begin(), tr.end());
    }
}
```

### 4.4 Î”Î¹Î¬Î³ÏÎ±Î¼Î¼Î±: Probe Execution Flow

```
LEGACY (Row-by-Row):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Main Thread:
â”‚
â”œâ”€ for i in 0..N:
â”‚   â”œâ”€ key = column.get(i)  â† SLOW (div/mod)
â”‚   â”œâ”€ entry = ht.lookup(key)
â”‚   â””â”€ if match: output.append()
â”‚
â””â”€ Done

Timeline: [get][lookup][get][lookup][get][lookup]...
          â””â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
          Overhead     Overhead


OPTIMIZED (Zero-Copy Parallel):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input Pages: [P0][P1][P2]...[PN]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
     â”‚ Atomic Ctr  â”‚ next_page = 0 â†’ 1 â†’ 2 â†’ ...
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                â”‚           â”‚          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚Thread 0â”‚      â”‚Thread 1â”‚  â”‚Thread 2â”‚  â”‚Thread 3 â”‚
â”‚        â”‚      â”‚        â”‚  â”‚        â”‚  â”‚         â”‚
â”‚Process â”‚      â”‚Process â”‚  â”‚Process â”‚  â”‚Process  â”‚
â”‚Page 0  â”‚      â”‚Page 1  â”‚  â”‚Page 2  â”‚  â”‚Page 3   â”‚
â”‚  â†“     â”‚      â”‚  â†“     â”‚  â”‚  â†“     â”‚  â”‚  â†“      â”‚
â”‚[Res0]  â”‚      â”‚[Res1]  â”‚  â”‚[Res2]  â”‚  â”‚[Res3]   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
    â”‚               â”‚           â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
             â”‚   MERGE     â”‚
             â”‚   Results   â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Timeline: Parallel execution, dynamic work distribution
```


## 5. Batch Output & Preallocation

### 5.1 Î ÏÏŒÎ²Î»Î·Î¼Î±: Incremental Append Overhead

#### Î‘ÏÏ‡Î¹ÎºÎ® Î ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ· (Î‘ÏÎ³Î®)

```cpp
// Per-match append with potential reallocation
for (auto& match : all_matches) {
    output_column.append(match.build_row);  // Potential resize
    output_column.append(match.probe_row);  // Potential resize
}

// Î¤Î¹ ÏƒÏ…Î¼Î²Î±Î¯Î½ÎµÎ¹ ÏƒÏ„Î¿ .append():
void append(int32_t value) {
    // Check if current page is full
    if (current_page_full()) {
        allocate_new_page();     // Expensive!
        update_metadata();       // Overhead
    }
    
    // Check if buffer needs resize
    if (buffer_full()) {
        resize_buffer();         // Reallocation!
        copy_old_data();         // Memory copy
    }
    
    // Finally write value
    write_value(value);
}
```

**Bottlenecks per append:**
- Page boundary checks
- Potential allocation
- Metadata updates
- Vector resizes
- Poor instruction cache (complex control flow)

**Total cost:** For 10M output rows â†’ 10M checks + reallocations

### 5.2 Î›ÏÏƒÎ·: Count â†’ Preallocate â†’ Fill

#### Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·

**Î‘ÏÏ‡ÎµÎ¯Î¿:** [src/execute_default.cpp:232-280](src/execute_default.cpp#L232-L280)

```cpp
// THREE-PHASE OUTPUT STRATEGY

// PHASE 1: COUNT - Determine total output size
size_t total_matches = 0;
for (size_t page_idx = 0; page_idx < num_pages; ++page_idx) {
    const int32_t* keys = page_data[page_idx];
    const size_t page_rows = page_sizes[page_idx];
    
    for (size_t i = 0; i < page_rows; ++i) {
        size_t match_count = 0;
        hashtable.probe(keys[i], &match_count);
        total_matches += match_count;
    }
}

// PHASE 2: PREALLOCATE - Reserve exact space needed
output_columns[0].reserve_exact(total_matches);  // Build row IDs
output_columns[1].reserve_exact(total_matches);  // Probe row IDs

// Pre-allocate pages (one-time allocation)
const size_t pages_needed = (total_matches + VALUES_PER_PAGE - 1) 
                           / VALUES_PER_PAGE;
output_columns[0].allocate_pages(pages_needed);
output_columns[1].allocate_pages(pages_needed);

// PHASE 3: FILL - Direct write with index
size_t out_idx = 0;
for (size_t page_idx = 0; page_idx < num_pages; ++page_idx) {
    const int32_t* keys = page_data[page_idx];
    const size_t page_rows = page_sizes[page_idx];
    const size_t base_row = page_offsets[page_idx];
    
    for (size_t i = 0; i < page_rows; ++i) {
        size_t match_count = 0;
        const auto* matches = hashtable.probe(keys[i], &match_count);
        
        // Direct write to pre-allocated space
        for (size_t m = 0; m < match_count; ++m) {
            output_columns[0].write_at_index(out_idx, matches[m].row_id);
            output_columns[1].write_at_index(out_idx, base_row + i);
            ++out_idx;
        }
    }
}

// Assert: out_idx == total_matches (perfect sizing)
```

### 5.3 Î”Î¹Î¬Î³ÏÎ±Î¼Î¼Î±: Output Strategy Comparison

```
LEGACY (Incremental Append):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

For each match:
â”‚
â”œâ”€ append(value)
â”‚   â”œâ”€ Check page boundary  â—„â”€â”€â”€ Per-match overhead
â”‚   â”œâ”€ Check buffer size
â”‚   â”œâ”€ Potential allocation â—„â”€â”€â”€ Expensive!
â”‚   â”œâ”€ Potential resize     â—„â”€â”€â”€ Copy old data
â”‚   â””â”€ Write value
â”‚
Timeline per 1000 matches:
[Check][Write][Check][Write][Check][ALLOC!][COPY!][Write]...
                                     â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜
                                     Stalls  Memory BW

Total: ~1000 checks + ~5-10 allocations


OPTIMIZED (Count-Preallocate-Fill):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PHASE 1 (COUNT):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scan all    â”‚
â”‚ matches     â”‚ Count: 1,234,567 matches
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
PHASE 2 (PREALLOCATE):
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Allocate exactly    â”‚
â”‚ 1,234,567 slots     â”‚ â—„â”€â”€â”€ ONE allocation
â”‚                     â”‚
â”‚ Page 0: [........]  â”‚
â”‚ Page 1: [........]  â”‚
â”‚ Page 2: [........]  â”‚
â”‚   ...               â”‚
â”‚ Page N: [........]  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
PHASE 3 (FILL):
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Direct write by     â”‚
â”‚ index (no checks)   â”‚ â—„â”€â”€â”€ Zero overhead
â”‚                     â”‚
â”‚ out[0] = val0       â”‚
â”‚ out[1] = val1       â”‚
â”‚ out[2] = val2       â”‚
â”‚   ...               â”‚
â”‚ out[1234567] = valN â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total: 0 checks + 1 allocation
```

### 5.4 Memory Layout Comparison

```
LEGACY (Fragmented):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Output Buffer Growth Timeline:

t=0:    [Buffer: 1K]        Initial
t=1:    [Buffer: 2K]        Resize + copy 1K
t=2:    [Buffer: 4K]        Resize + copy 2K
t=3:    [Buffer: 8K]        Resize + copy 4K
t=4:    [Buffer: 16K]       Resize + copy 8K
  ...
t=N:    [Buffer: 1.2M]      Resize + copy 600K

Total copies: 1K + 2K + 4K + 8K + ... = O(N) data copied
Memory allocations: log(N) allocations


OPTIMIZED (Contiguous):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Output Buffer: Single Allocation

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [1.2M allocated once]                 â”‚
â”‚  â”‚                                     â”‚
â”‚  â””â”€ All writes go here (no resize)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total copies: 0 (data written once)
Memory allocations: 1 allocation
```



## 6. Parallel Probing

### 6.1 Adaptive Parallelization Strategy

#### Î ÏÏŒÎ²Î»Î·Î¼Î±: Thread Overhead vs. Speedup

**Dilema:**
- Small datasets: Thread overhead > parallelism benefit
- Large datasets: Parallelism critical for performance

**Î›ÏÏƒÎ·:** Adaptive threshold-based strategy

#### Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·

**Î‘ÏÏ‡ÎµÎ¯Î¿:** [src/execute_default.cpp:190-230](src/execute_default.cpp#L190-L230)

```cpp
// Adaptive parallelization threshold
static constexpr size_t PARALLEL_PROBE_THRESHOLD = (1 << 18);  // 262,144 rows

void execute_probe_phase(
    const Column* probe_column,
    const std::vector<size_t>& page_offsets,
    UnchainedHashTable& ht,
    std::vector<OutPair>& results) {
    
    const size_t total_rows = page_offsets.back();
    
    // Adaptive decision
    if (total_rows < PARALLEL_PROBE_THRESHOLD) {
        // SEQUENTIAL: Low overhead, good cache locality
        probe_sequential(probe_column, page_offsets, ht, results);
    } else {
        // PARALLEL: Work-stealing for load balancing
        probe_parallel_work_stealing(
            probe_column, page_offsets, ht, results
        );
    }
}
```



## 7. Single-Pass Hashtable Build

### 7.1 Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÏÎ½

#### STRICT Mode: Partition-Based Build (Î Î¿Î»ÏÏ€Î»Î¿ÎºÎ¿)

**Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ®:** Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎµ partitions Î³Î¹Î± thread-safety ÎºÎ±Î¹ ÎºÎ±Î»ÏÏ„ÎµÏÎ· cache locality.

```cpp
// PHASE 1: PARTITION (Parallel)
// Each thread creates local partitions
std::vector<std::vector<std::vector<HashEntry>>> thread_partitions(nthreads);

parallel_for(num_entries, [&](size_t tid, size_t i) {
    const auto& entry = entries[i];
    const size_t partition = hash(entry.key) >> shift_bits;
    thread_partitions[tid][partition].push_back(entry);
});

// BARRIER: All threads must finish partitioning
synchronize_threads();

// PHASE 2: MERGE (Parallel - per partition)
parallel_for(num_partitions, [&](size_t tid, size_t part_idx) {
    // Merge all thread-local partitions for this partition
    std::vector<HashEntry> merged;
    for (size_t t = 0; t < nthreads; ++t) {
        merged.insert(merged.end(),
                     thread_partitions[t][part_idx].begin(),
                     thread_partitions[t][part_idx].end());
    }
    
    // Sort by hash for better locality
    std::sort(merged.begin(), merged.end(), 
             [](const auto& a, const auto& b) { 
                 return hash(a.key) < hash(b.key); 
             });
    
    // Build hashtable for this partition
    build_partition(part_idx, merged);
});
```

**ÎšÏŒÏƒÏ„Î¿Ï‚:**
- 2 Ï†Î¬ÏƒÎµÎ¹Ï‚ Î¼Îµ barriers (synchronization overhead)
- Î•Î½Î´Î¹Î¬Î¼ÎµÏƒÎµÏ‚ Î´Î¿Î¼Î­Ï‚ (thread_partitions)
- Merge overhead
- Sort overhead

**Î§ÏÏŒÎ½Î¿Ï‚ (113 queries):** 24.0s

#### OPTIMIZED Mode: Single-Pass Build (Î‘Ï€Î»ÏŒ)

**Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ®:** Î‘Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î® Î±Ï€ÏŒ pages ÏƒÏ„Î¿ hashtable, Ï‡Ï‰ÏÎ¯Ï‚ partitions.

```cpp
// SINGLE PHASE: Direct insert from pages
void build_from_zero_copy_int32_simple_parallel(
    const Column* src_column,
    const std::vector<size_t>& page_offsets,
    size_t num_rows) {
    
    const size_t num_pages = page_offsets.size() - 1;
    
    // Pre-allocate hashtable (one-time)
    reserve(num_rows);
    
    // Parallel page processing
    parallel_for_work_stealing(num_pages, 
        [&](size_t tid, size_t page_idx) {
            const Page* page = src_column->get_page(page_idx);
            const int32_t* data = extract_int32_data(page);
            
            const size_t start_row = page_offsets[page_idx];
            const size_t end_row = page_offsets[page_idx + 1];
            const size_t page_rows = end_row - start_row;
            
            // Direct insert (thread-safe hashtable)
            for (size_t i = 0; i < page_rows; ++i) {
                insert_direct(data[i], start_row + i);
            }
        });
}
```

**ÎšÏŒÏƒÏ„Î¿Ï‚:**
- 1 Ï†Î¬ÏƒÎ· (no synchronization overhead)
- ÎœÎ·Î´ÎµÎ½Î¹ÎºÎ­Ï‚ ÎµÎ½Î´Î¹Î¬Î¼ÎµÏƒÎµÏ‚ Î´Î¿Î¼Î­Ï‚
- ÎœÎ·Î´ÎµÎ½Î¹ÎºÏŒ merge overhead
- ÎœÎ·Î´ÎµÎ½Î¹ÎºÏŒ sort overhead

**Î§ÏÏŒÎ½Î¿Ï‚ (113 queries):** 10.2s

### 7.2 Î”Î¹Î¬Î³ÏÎ±Î¼Î¼Î±: Build Architecture Comparison

```
STRICT (Partition-Based):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INPUT PAGES
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚              â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚Thread 0â”‚   â”‚Thread 1â”‚    â”‚Thread 2â”‚    â”‚Thread 3â”‚
â”‚        â”‚   â”‚        â”‚    â”‚        â”‚    â”‚        â”‚
â”‚ Local  â”‚   â”‚ Local  â”‚    â”‚ Local  â”‚    â”‚ Local  â”‚
â”‚ Part[0]â”‚   â”‚ Part[0]â”‚    â”‚ Part[0]â”‚    â”‚ Part[0]â”‚
â”‚ Part[1]â”‚   â”‚ Part[1]â”‚    â”‚ Part[1]â”‚    â”‚ Part[1]â”‚
â”‚ Part[2]â”‚   â”‚ Part[2]â”‚    â”‚ Part[2]â”‚    â”‚ Part[2]â”‚
â”‚  ...   â”‚   â”‚  ...   â”‚    â”‚  ...   â”‚    â”‚  ...   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚            â”‚             â”‚             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
          â”‚   BARRIER   â”‚ â† Wait for all threads
          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                          â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Merge      â”‚         â”‚ Merge      â”‚   â”‚ Merge      â”‚
â”‚ Part 0     â”‚         â”‚ Part 1     â”‚   â”‚ Part 2     â”‚
â”‚ (all T's)  â”‚         â”‚ (all T's)  â”‚   â”‚ (all T's)  â”‚
â”‚   â†“        â”‚         â”‚   â†“        â”‚   â”‚   â†“        â”‚
â”‚ Sort       â”‚         â”‚ Sort       â”‚   â”‚ Sort       â”‚
â”‚   â†“        â”‚         â”‚   â†“        â”‚   â”‚   â†“        â”‚
â”‚ Build HT   â”‚         â”‚ Build HT   â”‚   â”‚ Build HT   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phases: 2 (Partition â†’ Merge)
Memory: 3x (local parts + merge + final)
Overhead: Barriers, sorting, merging


OPTIMIZED (Single-Pass):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INPUT PAGES
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚              â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚Thread 0â”‚   â”‚Thread 1â”‚    â”‚Thread 2â”‚    â”‚Thread 3â”‚
â”‚        â”‚   â”‚        â”‚    â”‚        â”‚    â”‚        â”‚
â”‚Page 0  â”‚   â”‚Page 1  â”‚    â”‚Page 2  â”‚    â”‚Page 3  â”‚
â”‚  â†“     â”‚   â”‚  â†“     â”‚    â”‚  â†“     â”‚    â”‚  â†“     â”‚
â”‚Direct  â”‚   â”‚Direct  â”‚    â”‚Direct  â”‚    â”‚Direct  â”‚
â”‚Insert  â”‚   â”‚Insert  â”‚    â”‚Insert  â”‚    â”‚Insert  â”‚
â”‚  â†“     â”‚   â”‚  â†“     â”‚    â”‚  â†“     â”‚    â”‚  â†“     â”‚
â””â”€â”€â”€â”¼â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¼â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”¼â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”¼â”€â”€â”€â”€â”˜
    â”‚            â”‚             â”‚             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   HASHTABLE    â”‚ â† Shared, thread-safe
              â”‚  (final dest)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phases: 1 (Direct Build)
Memory: 1x (final only)
Overhead: Zero
```




### Î¤ÎµÎ»Î¹ÎºÎ® Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® (OPTIMIZED)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OPTIMIZED_PROJECT Hash Join Engine         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT
  â”‚
  â”œâ”€ Zero-Copy Page Access
  â”‚   â””â”€ Direct pointers (no division/modulo)
  â”‚
  â”œâ”€ Single-Pass Build
  â”‚   â”œâ”€ Pre-allocate hashtable
  â”‚   â””â”€ Direct insert from pages
  â”‚
  â”œâ”€ Parallel Probe (Adaptive)
  â”‚   â”œâ”€ Work-stealing (large data)
  â”‚   â””â”€ Sequential (small data)
  â”‚
  â””â”€ Batch Output
      â”œâ”€ Count matches
      â”œâ”€ Pre-allocate
      â””â”€ Direct fill

OUTPUT
```


